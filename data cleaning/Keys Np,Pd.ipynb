{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ec85bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e760af72",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1.import numpy as np\n",
    "\n",
    "2.Converting the python_list to a numpy array\n",
    "numpyarray=np.array(list)\n",
    "numpyarray\n",
    "\n",
    "3.Concatenation array\n",
    " Z = X + Y \n",
    "    return Z\n",
    "\n",
    "#Shape, Size and Data Type of an Array\n",
    "4.#Size of an Array\n",
    "arr.size\n",
    "\n",
    "5.Data Types of Array\n",
    "arr.dtype\n",
    "\n",
    "6.Shape of an Array\n",
    "arr.shape\n",
    "\n",
    "7.Dimension of an Array\n",
    "arr.ndim\n",
    "\n",
    "8. type of NumPy array\n",
    "arr.dtype\n",
    "\n",
    "9.Creating Basic NumPy Arrays\n",
    "arr1=np.array([[1,2,5,7],[5,2,7,6],[6,2,0,8]])\n",
    "arr1\n",
    "\n",
    "10.create collection of continuous integers\n",
    "np.arange(5)\n",
    "\n",
    "11.#Zeros( )\n",
    "arr=np.zeros(5)\n",
    "arr\n",
    "\n",
    "12.#ones( )\n",
    "arr=np.ones(5)\n",
    "arr\n",
    "one1=np.ones([5,5])*10\n",
    "one1\n",
    "\n",
    "13.values which are equally spaced from each other.\n",
    "#linspace( )\n",
    "#arr=np.linspace(start=5,stop=6,num=7)\n",
    "arr=np.linspace(5,6,4)\n",
    "arr\n",
    "\n",
    "14.#Add, Remove and Sort\n",
    "np.append\n",
    "arr=np.array([2,5,7,3,4,6])\n",
    "np.append(arr,15) # add an element\n",
    "np.append(arr,[5,6,7]) #You can also add a list of elements\n",
    "\n",
    "15.#Removing an Element\n",
    "np.delete(arr,2)\n",
    "\n",
    "16.#Sorting an Array\n",
    "np.sort(arr)\n",
    "\n",
    "17.#Reshaping an Array \n",
    "np.reshape()\n",
    "arr=np.arange(24)\n",
    "#np.reshape(arr,(8,3))\n",
    "np.reshape(arr,(6,4))\n",
    "np.reshape(arr,(12,2))\n",
    "#OR\n",
    "#arr.reshape(6,4)\n",
    "\n",
    "18.#Positive Indexing\n",
    "arr=np.arr([[10,20,30,40],[1,2,3,4]])\n",
    "arr[1,2]\n",
    "\n",
    "19.Positive Index Intervals in a NumPy Array / slicing an array. array_name[s_row:e_row,s_col:e_col]\n",
    "arr[1:3,2:4] # n-1\n",
    "#OR\n",
    "#arr[1:3,2:]\n",
    "\n",
    "20.#Negative Indexing\n",
    "arr[-3:-1,-2:]\n",
    "\n",
    "21.Striding [start index: End index :Stride]\n",
    "arr[0:4:3]\n",
    "#OR\n",
    "arr[0::3]\n",
    "\n",
    "22.#2D Array Numpy\n",
    "arr2d = np.arange(16).reshape(4,4)\n",
    "arr2d\n",
    "*arr2d_1= np.arange(1,17)#1-16\n",
    "\n",
    "23.#Array 3D\n",
    "arr3d = np.arange(50).reshape(2,5,5)# depth, row, column\n",
    "arr3d\n",
    "\n",
    "24.Horizontal Stack/horizontally (i.e. column wise) to make a single array.Concatenate\n",
    "a = np.hstack([arr2d_1,arr2d_2])\n",
    "\n",
    "25.Vertically\n",
    "a = np.vstack([arr2d_1,arr2d_2])\n",
    "\n",
    "26.#hsplit\n",
    "np.hsplit(arr_new,2)\n",
    "function split an array into multiple sub-arrays horizontally (column-wise).\n",
    "\n",
    "27.vsplit\n",
    "np.vsplit(arr_new,3)\n",
    "#vertically\n",
    "\n",
    "28.random.randint\n",
    "a = np.random.randint(10, size=(5, 3))\n",
    "specified shape and fills it with random integers\n",
    "\n",
    "ii)arr2d = np.random.randint(5,10,(5,5)) ## 5=here,start with 5 and 10=n-10\n",
    "\n",
    "29.Condition apply on random.randint\n",
    "arr2d>5\n",
    "arr2d[arr2d>5]\n",
    "arr2d[(arr2d>5) & (arr2d<8)]\n",
    "arr2d[(arr2d>5) & (arr2d%2==0)]\n",
    "arr2d[(arr2d>5) | (arr2d%2==0)]\n",
    "\n",
    "30.np.where()\n",
    "function returns the elements in an input array where the given condition is satisfied.\n",
    "np.where(arr2d>5,9,arr2d)\n",
    "\n",
    "31..masking or condition based data selection\n",
    "a[a>5]\n",
    "\n",
    "32.import pandas as pd\n",
    "\n",
    "33.read data\n",
    "data=pd.read_csv(\"car_data.csv\")\n",
    "data\n",
    "sales=pd.read_excel(\"SaleData.xlsx\")\n",
    "sales\n",
    "\n",
    "34.call element of any column\n",
    "data[data.name=='Hyundai Santro Xing XO eRLX Euro III']\n",
    "\n",
    "35.[{a,a*2}  for a in range(10)]\n",
    "\n",
    "36.[{a: a.upper()} for a in \"saulat\"]\n",
    "\n",
    "37.#Concatenating Arrays\n",
    "arr2d_a = np.arange(25).reshape(5,5)\n",
    "arr2d_b = np.arange(25,50).reshape(5,5)\n",
    "\n",
    "38.merged_array = np.concatenate([arr2d_a,arr2d_b])  #horizontal add\n",
    "merged_array\n",
    "\n",
    "39.merged_array = np.concatenate([arr2d_a,arr2d_b],axis=1)\n",
    "merged_array\n",
    "#horizontal add axis=1 ==== layta\n",
    "#vertical add axis=0 ===== khara\n",
    "\n",
    "40.newArray= np.split(arr2d_c,2,axis=0)\n",
    "newArray\n",
    "#split the array in 2 sub=arrays in horizonatally ,layta howa\n",
    "\n",
    "41.newArray= np.split(arr2d_c,2,axis=1)\n",
    "newArray\n",
    "#split the array in 2 sub=arrays in vertical ,khara howa\n",
    "\n",
    "42.A,B= np.split(arr2d_c,2,axis=1)\n",
    "B\n",
    "\n",
    "43.arr2d_e=np.arange(64).reshape(8,8)\n",
    "a,b,c,d=np.split(arr2d_e,4,axis=1)\n",
    "d\n",
    "\n",
    "44.ones_like\n",
    "a = np.array([1,2,3,4,5,6])\n",
    "np.ones_like(a)\n",
    "\n",
    "45.#full and fill\n",
    "np.full(10,5)\n",
    "#10 times ,5 likh du\n",
    "np.full((5,5), fill_value=10,)\n",
    "# but yahan matlab size 5 row ,5 column and fill with value 10\n",
    "\n",
    "46.numpy.empty() function\n",
    "np.empty((4,4))\n",
    "to create a new array of given shape n type,without initializing entriesvalues will be filled in later\n",
    "\n",
    "47.Identity MAtrix\n",
    "np.identity(5)\n",
    "principal diagonals are one,and all other elements are zeros. I\n",
    "\n",
    "48.pd series\n",
    "s1 = pd.Series([10,12,14,20,22,24])\n",
    "s1\n",
    "#print(type(s1))\n",
    "#s1.size Ans 6\n",
    "#s1.shape Ans(6,)\n",
    "#s1[3]\n",
    "\n",
    "49.s1.index\n",
    "Ans:RangeIndex(start=0, stop=6, step=1)\n",
    "\n",
    "50.s1.values\n",
    "\n",
    "51.s1 = pd.Series([10,12,14,20,22,24], index=[\"Anday\", \"Burger\", \"Apples\",\"Mangoes\", \"Alo\", \"Tomato\"])\n",
    "s1\n",
    "s1[\"Anday\"]\n",
    "#Ans 10\n",
    "s1[\"Apples\":\"Tomato\"]\n",
    "\n",
    "52.#Importing Modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "53.s1.isnull()\n",
    "#Returns a Boolean value\n",
    "#*index'empty' krna pr np.nan ,true aya ,warna na true na false dy raha tha\n",
    "\n",
    "54.converting dictionary into data frame \n",
    "data=pd.DataFrame(dictionary)\n",
    "data\n",
    "Ans:\n",
    "  roll\tname\tcourse\tScore\tResult\n",
    "0\t1\tatif\tPython\t90.0\tPass\n",
    "1\t2\tmohid\tWeb\t    45.0\tFail\n",
    "\n",
    "55.Retriveing a single columns(series) from data frame\n",
    "data['Score']\n",
    "*1 dimension/series\n",
    "\n",
    "56.data type\n",
    "type(data['Score'])\n",
    "\n",
    "57. selecting more than one column from a data frame \n",
    "type(data[[\"Score\",\"Result\"]])\n",
    "#*inner square brackets =Python list with column names, outer brackets =data from a pandas DataFrame.\n",
    "#represent [[]]\n",
    "\n",
    "58. adding a new colums in current data frame\n",
    "data['Class Day']=['Monday', 'Sunday', 'Sunday', 'Sunday', 'Monday', 'Monday', 'Friday', 'Friday', 'Sunday', 'Thursday']\n",
    "data\n",
    "\n",
    "59.# selecting all data but providing a new sequence of columns\n",
    "data[['roll', 'name', 'Class Day', 'course', 'Score', 'Result']]\n",
    "\n",
    "60.returns column names \n",
    "data.columns\n",
    "\n",
    "61. overwrting the old column list with a NEW LIST OF column names\n",
    "data.columns = ['roll', 'name', 'course', 'score', 'result', 'class_day','Percentage']\n",
    "data\n",
    "\n",
    "62.inplace=True\n",
    "changes the default behaviour such that the operation on the dataframe doesnâ€™t return anything,\n",
    "\n",
    "63.#inplace=False\n",
    "Alternatively, when using inplace=False (which is the default behaviour) \n",
    "the dataframe operation returns a copy of the dataframe, leaving the original data intact\n",
    "\n",
    "64. Rename the column\n",
    "data.rename(columns={'class_day':'classday'},inplace=True)\n",
    "data\n",
    "\n",
    "65. returns max value from provided column .max()\n",
    "data.score.max()\n",
    "\n",
    "66.checks if there is NAN value in column .isnull()\n",
    "data.score.isnull() # Ans Boolen\n",
    "\n",
    "67.us null wala ka data du\n",
    "data[data.score.isnull()]\n",
    "\n",
    "68.sum()\n",
    "#sum kara ga ka ketna isnull hein column score mein\n",
    "data.score.isnull().sum()\n",
    "\n",
    "69.#isnull in different ways\n",
    "i)data.isnull().sum() #Ans course 1 ,source 1 pora data mein jahan jahan NaN ho ga ,\n",
    "#us column ka aga mein total Nan count kr dy ga\n",
    "roll          0\n",
    "name          0\n",
    "course        1\n",
    "score         1\n",
    "result        0\n",
    "class_day     0\n",
    "Percentage    0\n",
    "dtype: int64\n",
    "\n",
    "ii)data.course.isnull().sum()# Ans 1\n",
    "iii)data.course.isnull() # course ke pori row mein boolean apply ,jahan Nan wahan True show kara ga,\n",
    "#warna false\n",
    "iiii)data[data.isnull()] #all data Nan ho gaya ,mujha chahya tha course ns core ka data ?\n",
    "\n",
    "70.max value ka index dy ga .argmax()\n",
    "data.score.argmax()\n",
    "\n",
    "71.data.score.mean()\n",
    "\n",
    "72.Standard deviation .std()\n",
    "data.score.std()\n",
    "\n",
    "73.variance .var()\n",
    "data.score.var()\n",
    "\n",
    "74.unique()\n",
    "#course ke row ke all values without duplicate\n",
    "data.course.unique()\n",
    "\n",
    "75.value_counts()\n",
    "# ya courses ketna students na lia howa hein\n",
    "data.course.value_counts()\n",
    "\n",
    "76.sales.Region\n",
    "sales.Region\n",
    "i)sales.Region.isnull().sum()\n",
    "ii)sales.Region.unique()\n",
    "iii)sales.Region.value_counts()\n",
    "\n",
    "77.values \n",
    "sales.Item.values\n",
    "#The values property returns all values in the DataFrame.\n",
    "\n",
    "78.data/sales.values\n",
    "#Pandas DataFrame.values attribute return a Numpy representation of the given DataFrame.\n",
    "\n",
    "79..head()\n",
    "returns the first 5 rows if a number is not specified\n",
    "#sales.head(10)\n",
    "\n",
    "80..sum()\n",
    "#sum of the row\n",
    "sales.Sale_amt.sum()\n",
    "\n",
    "81.sales[['Manager','Region']]\n",
    "\n",
    "82.sales[sales.Sale_amt==sales.Sale_amt.max()][['Manager','Region']]\n",
    "*#sales.Sale_amt==sales.Sale_amt.max() Ans max value True ,others False\n",
    "\n",
    "83.sales[sales.SalesMan==\"Alexander\"]['Sale_amt'].sum()\n",
    "\n",
    "84.sales[sales.OrderDate<='2018-03-31']['Sale_amt'].sum()\n",
    "\n",
    "85.sheet name\n",
    "df=pd.read_excel(\"SaleData.xlsx\",sheet_name=1)\n",
    "\n",
    "86.header=0 header=none\n",
    "0=columns name are nt data part\n",
    "\n",
    "87.df=pd.read_excel(\"SaleData.xlsx\",index_col=\"OrderDate\")\n",
    "df\n",
    "#order date become index;where df is data frame\n",
    "\n",
    "88.#Selecting a particular column from data\n",
    "df['Item']\n",
    "\n",
    "89. usecols=[] #Selecting a more then one column from data\n",
    "\n",
    "df=pd.read_excel(\"SaleData.xlsx\",usecols=[\"Region\",\"SalesMan\",\"Sale_amt\"])\n",
    "df\n",
    "sara df ka data na load krna para\n",
    "\n",
    "90.#Selecting more then one column\n",
    "df=pd.read_excel(\"SaleData.xlsx\",index_col=\"OrderDate\")\n",
    "df\n",
    "df[[\"Region\",\"Manager\",\"Item\",\"Units\"]]\n",
    "\n",
    "91..loc #SLICING of Columns: \n",
    "\n",
    "slice means copy\n",
    "df2=df.loc[:,[\"Region\",\"Unit_price\"]]\n",
    "df2\n",
    "\n",
    "92.**List Conprehension\n",
    "  Output                     Collection                   Condition\n",
    "  x+1                        for x in range(5)            if x%2 == 0\n",
    "  DO this                    for this Collection          in this Situation\n",
    "List comprehension is an easy to read, compact, and elegant way of creating a list\n",
    "\n",
    "93.Adding a Columns to existing data also using import math and math.sqrt() and round()/withdf\n",
    "Add new column with values;#like data['Class Day']=['Monday', 'Sunday']\n",
    "import math\n",
    "df['falto_col']=[math.sqrt(a) for a in range(45)] \n",
    "df.round()\n",
    "\n",
    "94.add tax column\n",
    "df['Tax_Applied']=[(a* .10) for a in df['Sale_amt']]\n",
    "df.round()\n",
    "\n",
    "95.Delete Column del\n",
    "del df[\"falto_col\"]\n",
    "df\n",
    "\n",
    "96..drop() delete more then one column\n",
    "df1=df.copy()\n",
    "df1\n",
    "df3 = df.drop(columns=[\"Region\",\"Unit_price\"])\n",
    "df3\n",
    "first make copy of df,then give range\n",
    "\n",
    "97.loc and iloc   Slicing column and Row\n",
    "#*We have two modes of indexing \n",
    "#Label : Header mein label chal raha\n",
    "#int indices :row mein index\n",
    "loc  == labels ;labels provide\n",
    "iloc == int indices;iloc mein slice kru tu int indices location base chalo\n",
    "\n",
    "df1.loc[1:20,'Region':'SalesMan'] #include last index\n",
    "\n",
    "df1.iloc[1:20,1:4] #n-1/not include last index\n",
    "\n",
    "98.FANCY Indexing\n",
    "\n",
    "df1.loc[[12,4,16,8,10],['Item','Unit_price']]\n",
    "#give row on ur wish\n",
    "\n",
    "99.#Now add Row\n",
    "#agar dataframe ka undar koe record add krna tu wo bhe data frame he hona chahya\n",
    "#numPy mein tu append kr dia krta tha\n",
    "#farzxi record\n",
    "#record=pd.DataFrame({\"OrderDate\":\"NaN\",\"Manager\":\"Naqv\",\"SalesMan\":\"SYed\"},index=[2])\n",
    "OR\n",
    "\n",
    "record =df1.iloc[0:1,:] # 0 row or us ka sara columns utha lu\n",
    "df1.add(record,axis=rows)\n",
    "\n",
    "100.EDA:Exploratary Data Analysis then Data Cleansing\n",
    "First, data analyize/Explore then data cleanding\n",
    "\n",
    "101.for explore\n",
    "car_data.shape\n",
    "car_data.head() #start ka 5 record\n",
    "\n",
    "102..tail()\n",
    "car_data.tail() #last ka 5 records\n",
    "\n",
    "103.info()\n",
    "car_data.info()\n",
    "#open all the data\n",
    "\n",
    "104.\n",
    "1.data hai us ke type valid hai ka nhe hai eg amount should be integer\n",
    "2.ub data ke quality ko check krna ka lia,check kru ga ka missing data ketna hai\n",
    "\n",
    "car_data.isnull.sum()\n",
    "3.Big Question : en missing record ka mein kia karu,either delete or either full ,on business logic\n",
    "if less data,cant delete\n",
    "\n",
    "105.#fillna \n",
    "#missing data  fill\n",
    "car_data.fillna(\"datamissing\")\n",
    "\n",
    "106.#dropna \n",
    "#missing data  drop()\n",
    "car_data.dropna()\n",
    "*but nt change in memory\n",
    "\n",
    "107.Change in Memory inplace=True OR save in new variable \n",
    "car_data.info() #to check the position of data\n",
    "car_data.dropna(inplace=True)\n",
    "car_data\n",
    "\n",
    "car_data.info()\n",
    "car_data.isnull().sum()\n",
    "\n",
    "108. drop_duplicates #Duplicated Records duplicated and drop_duplicates \n",
    "#* whole column same consider duplicate or 3 record out of 50 consider duplicate \n",
    "1.#car_data.duplicated() # es tahra krna sai True ,False aya ga, sum() lagana chahya\n",
    "2.#car_data[car_data.duplicated()] #pr duplicate record ka complete data\n",
    "3.#car_data.duplicated().sum() #es tarha total bata dy ga ketna duplicate hein\n",
    "\n",
    "1.#bydefault lekha howakeep:dropkeep=first\n",
    "#means first duplicate ko rakho,us ka bayd jo aya ura du\n",
    "2.#by default ignore index:bool=false\n",
    "#duplicate drop krna pr jo index ke jaga bache..necha wala index ko opar ly au\n",
    "\n",
    "car_data.duplicated().sum()\n",
    "\n",
    "car_data.drop_duplicates(inplace=True)\n",
    "car_data\n",
    "#* abhe sub kam Ram ,jupyter pr chal raha hai..excel file mein koe change nhe a raha\n",
    "\n",
    "109.Make name small\n",
    "car_data.name=car_data.name.str.split().str[:3].str.join('')\n",
    "car_data\n",
    "car_data sai bola name ka column ly kr au,wo series tha,us ko string kia,us ko split kia\n",
    "#wo list bun gaya,us ko again list sai string banaya and slice kr dia\n",
    "car_data.name.str.split().str[:3]\n",
    "#*jub list ko bola string ho jau,tu ub us ke akk ak entry pr apply ho gaya slice eg index\n",
    "#kuu ka vecotized operations hai\n",
    "error bc list mein join ka function nhe\n",
    "car_data.name.str.split().str[:3].str.join('')\n",
    "#tu phr es ko again str dia,str.join\n",
    "#ub es ko save kr du car_data.name = \n",
    "#*agar car_data= kia tu pora data ,akk coulmn ho jaya ga\n",
    "car_data.name=car_data.name.str.split().str[:3].str.join('')\n",
    "car_data\n",
    "(Need to Understand)\n",
    "\n",
    "110.  astype year type object to Integer\n",
    "car_data.year.dtype #Ans O\n",
    "\n",
    "car_data.year.astype('int')\n",
    "\n",
    "car_data.year=car_data.year.astype('int')\n",
    "car_data.year\n",
    "#ub es ko update kr deta hein car_data.year mein\n",
    "\n",
    "111.#str.isnumeric()  and use of tilde ~\n",
    "#The isnumeric() method returns True if all the characters are numeric (0-9), otherwise False.\n",
    "#tu hum sirf interger value mangwa sakta hein,agar year mein string etc bhe mix hu tu\n",
    "car_data[car_data.year.str.isnumeric()]\n",
    "\n",
    "#** agar tilde laga du i.e ~ ,tu it means ka jahan jahan true wo nhe lena.ulta kara ga\n",
    "#yahan pr matlaba jahan jahan numeric wo nhe lena\n",
    "car_data[~car_data.year.str.isnumeric()]\n",
    "\n",
    "112.car_data.Price.value_counts()\n",
    "#value.count sai ,count batata ketne bar aee hein\n",
    "\n",
    "113. that particular data not taking,Not Dropping ,not filling by ZERO\n",
    "car_data[~car_data.Price==\"Ask For Price\"]\n",
    "OR \n",
    "car_data[car_data.Price!=\"Ask For Price\"]\n",
    "*take data not equal to \"Ask for price\" in price list\n",
    "\n",
    "114. type Object (, replace) to Float\n",
    "car_data.Price=car_data.Price.str.replace(\",\",\"\").astype(float)\n",
    "*its not int,its string bc of comma,if nt comma,string can directly convert string to integer\n",
    "*replaced comma with nothing\n",
    "\n",
    "115.\n",
    "car_data.kms_driven.str.replace(\" kms\",\"\").str.replace(\",\",\"\").astype(float)\n",
    "* 2 string replace.first \" kms\",space kms and then comma\n",
    "\n",
    "**car_data.kms_driven=car_data.kms_driven.str.replace(\" kms\",\"\").str.replace(\",\",\"\").astype(float)\n",
    "#update result check krna ka bayd kr raha,warna galat data update ho jaya ga\n",
    "\n",
    "116.Save Permanent to_csv\n",
    "car_data.to_csv(\"cleaned_data.csv\")\n",
    "\n",
    "117.Data Cleaning and Preparation\n",
    "#Handling missing Data - fill missing data - drop missing data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "118.dropna    fillna     isnull    notnull\n",
    "#axis=0 means pori row drop kr dyne hai\n",
    "#axis=1 means pora column drop kr dena hai\n",
    "\n",
    "119. isna()\n",
    "data=pd.read_excel(\"SaleData1.xlsx\")\n",
    "data\n",
    "data.isna().sum()\n",
    "#tu humyn column wise bata deta hai,kahan ketna missing hein\n",
    "\n",
    "120. dataframe.dropna(axis, how, thresh, subset, inplace)\n",
    "\n",
    "121.dropna axis=0\n",
    "*As one column was all Nan ,so al rows deleted\n",
    "*so not inplace,so didnt permanent delete\n",
    "\n",
    "122. dropna axis=1\n",
    "data.dropna(axis=1)\n",
    "*ub ya masla ho gaya,jis mein ak NaN tha..us ko bhe ura dia.halaka hamra khayal mein sirf extra ko\n",
    "uraya ga\n",
    "\n",
    "123. how='all' how ='any'\n",
    "data.dropna(axis=1 ,how='all')\n",
    "how='all' all nhe urana \n",
    "data.dropna(axis=1 ,how='all')\n",
    "#extra ko ura dia,agar any krta tu sb ko ura deta;jis mein all Nan hu; any=jis kese mein  nan ho\n",
    "\n",
    "\n",
    "124. thresh (thresh understand reverse)\n",
    "data.dropna(axis=1 ,thresh=40)\n",
    "* if axis=1 ,column mein 52,12 wale 40 values true hein tu nhe urana\n",
    "** matlab jis mein 40 tuk non null value hu ,unha rehna du,unha na urnana\n",
    "\n",
    "125. subset \n",
    "data.dropna(axis=1 ,thresh=50 ,subset=['SalesMan','Item'])\n",
    "\n",
    "126. fillna\n",
    "data.fillna('missing')\n",
    "OR\n",
    "data.fillna(200)\n",
    "#abhe simple missing sai fill kr dia,hur jaga missing lekha howa a gaya\n",
    "\n",
    "127.Hardcore data fill by using Dictionary\n",
    "#problem 200 Region mein bhe a gaya\n",
    "data.fillna({'OrderDate':'2019-12-31','Region':'Central','Manager':'saulat',\n",
    "             'SalesMan':'Shahid','Item':'Cell Phone','Units':'100','Unit_price':'225.0',\n",
    "             'Sale_amt':'63494','Extra':200})\n",
    "\n",
    "128. data fill Statistically OR true representation  USING MODE (for non-numeric value)\n",
    "data.fillna({'Region':data.Region.mode()[0],'Manager':data.Manager.mode()[0],\n",
    "             \"SalesMan\":data.SalesMan.mode()[0],\"Item\":data.Item.mode()[0],\n",
    "             \"Units\":data.Units.mean(),\"Unit_price\":data.Unit_price.median(),\n",
    "             \"Sale_amt\":data.Sale_amt.median(),\"Extra\":300})\n",
    "\n",
    "# Mode use kara ga,jo item sub sai ziada bar aya howa hai wo fill kr du ,Nan ke jaga\n",
    "data.fillna({'Region':data.Region.mode(),})\n",
    "#* kaisa fill kru,dictionary ka undar region: ke value mein,data ka undar jau-region ka column\n",
    "#uthao-or us ka mode nekal du,or jo most repeated value aya mode sai.osa fillna ka zareya fill\n",
    "#kr du\n",
    "****mode() returns a Series (a type of pandas DataFrame), not a single value\n",
    "\n",
    "129. data fill Statistically OR true representation  USING Mean and Median (numeric value)                     \n",
    "#Mean: Units numeric hai,es lia average nekala ga,or average nekalta mean sai\n",
    "#lakin agar data mein variance ziada hota ,outliers hota tu Median nekalta\n",
    "#Unit_Price mein outliers a raha tu mediana lagaya ga\n",
    "\n",
    "130. if multiple modes and result in series (0 Central) convert in string\n",
    "#Note es na data update nhe kia,,bc ya series ke form mein result la raha(with index)\n",
    "#,Mode,Median,Mean sb series ke form mein result a raha\n",
    "i.e 0 Central\n",
    "# tu ya 0 Central ,du alag column kaisa fill karyan central mein ya index kaisa fill kara\n",
    "# **humyn tu string chahya or ya series hai\n",
    "eg Central,South,North 5 5 5 times so index 0 central ,index 1 south, index 2 north\n",
    " *tu ap na jo value uthane us ka index dy du ga eg Region':data.Region.mode()[2]\n",
    "\n",
    "data.fillna({'Region':data.Region.mode()[0],'Manager':data.Manager.mode()[0],\n",
    "             \"SalesMan\":data.SalesMan.mode()[0],\"Item\":data.Item.mode()[0],\n",
    "             \"Units\":data.Units.mean(),\"Unit_price\":data.Unit_price.median(),\n",
    "             \"Sale_amt\":data.Sale_amt.median(),\"Extra\":300})\n",
    "\n",
    "131.Class Task\n",
    "#a)Download and load the dataset in pandas from\n",
    "import pandas as pd\n",
    "data=pd.read_excel('employee.xlsx',index_col='Serial')\n",
    "data\n",
    "\n",
    "#b)Write the query that shows how many duplicate records are there?Further fetch all the duplicate records.\n",
    "#how many duplicate record\n",
    "data.duplicated().sum()\n",
    "#show that records\n",
    "#data.duplicated() #Ans will be in true false\n",
    "data[data.duplicated()]\n",
    "\n",
    "#c)\tWrite the query to find the count of each designation in the data? \n",
    "data.Designation.value_counts() #maloon ho ga,deisgnation mein kes position pr ketna log hein\n",
    "\n",
    "#d)\tRemove the duplicate record from the employee data frame.\n",
    "data.drop_duplicates()\n",
    "data # es na 3 duplicate nekal dia,phr bhe 18 ka 18 nazar a raha kuu ka inplace nhe kia,\n",
    "#permanent duplicate remove nhe howa\n",
    "data.drop_duplicates(inplace=True)\n",
    "data\n",
    "\n",
    "#e)\tWrite the code to fill the missing value of the Salary, Department, Age columns? Discuss your \n",
    "#choice of value, like a hard coded value, a mean, median, mode of the column?\n",
    "data.info()\n",
    "data.isnull().sum()\n",
    "data.fillna({'Department':data.Department.mode()[0],'Age':data.Age.mean(),'Salary':data.Salary.median()},inplace=True)\n",
    "*department ka name hein.no median,only mode ;series aya ge us ka zero index utha lu\n",
    "\n",
    "#f)\tWrite the code to find the average salary of the accounts department\n",
    "data[data.Department=='Accounts']\n",
    "data[data.Department=='Accounts']['Salary']\n",
    "data[data.Department=='Accounts']['Salary'].mean()\n",
    "\n",
    "\n",
    "#g)\tWhat the department and Emp_ID of the manager having the highest salary\n",
    "data[data.Designation=='Manager']\n",
    "data[data.Designation=='Manager']['Salary'].max()\n",
    "data[data.Salary==200000.0]\n",
    "data[data.Salary==data[data.Designation=='Manager']['Salary'].max()]\n",
    "# data[data.Salary==data[data.Designation=='Manager']['Salary'].max()]['Department','Emp_Id'] #Error\n",
    "*bc more then once so made list\n",
    "like [  ['Department','Emp_Id']  ]\n",
    "data[data.Salary==data[data.Designation=='Manager']['Salary'].max()][['Department','Emp_ID']]\n",
    "\n",
    "#h)\tWhat is the average age of the Officers in the company?\n",
    "data[data.Designation=='officer']\n",
    "data[data.Designation=='officer']['Age']\n",
    "data[data.Designation=='Officer']['Age'].mean()\n",
    "\n",
    "#i)\tWrite the query to show how many employees are working in IT department?\n",
    "data.Department.value_counts()\n",
    "data[data.Department==\"IT\"].shape[0] #Ans (7,5) means 7rows and 5 columns,tu mujha sirf row uthane hai\n",
    "# (Need to Understand)\n",
    "#OR\n",
    "data[data.Department==\"IT\"]['Emp_ID'].count()\n",
    "#OR\n",
    "\n",
    "(data.Department=='IT').sum()\n",
    "\n",
    "# OR best way is below both\n",
    "len(data[data.Department=='IT'])\n",
    "\n",
    "# OR\n",
    "data.Department[data.Department==\"IT\"].count()\n",
    "\n",
    "#j)\tAfter cleaning the employee data set, save the data set in csv format in a file\n",
    "#save krna ka tareka\n",
    "data.to_excel(\"cleaned_employee.xlsx\")\n",
    "\n",
    "132.#Note Float ; ordinal numbers type\n",
    "#*agar sare values integer hein.us mein ak bhe float a kr gera,tu pori series dekhaya ga float\n",
    "#* ese tarha agar sara integer hein or ak NaN bhe gaee,tu NaN ke waja sai sara float hu jayn ga\n",
    "\n",
    "#phone number,numbers tu hota hein but wo integer nhe hota,ordinal number nhe hota,nominal numbers\n",
    "#hota hein,un ke data type rakho object or string\n",
    "#bohat sara phone number lekha hun ,tu us ko order nhe kr sakta,sort nhe kr sakta,wo numbers hein\n",
    "#wo number lekha howa integer mein,kia koe phone number 0 sai start dekha raha ho ga,nhe.\n",
    "#us ke data type rakhta,object ya string\n",
    "\n",
    "133.# NOW COMPLEX DATA CLEANING\n",
    "#EXPLORATORY DATA ANALYSIS\n",
    "#Exploratory data analysis of Housing Data\n",
    "data=pd.read_csv(\"Bengaluru_House_Data.csv\")\n",
    "data\n",
    "data.shape\n",
    "data.columns\n",
    "data.sample(10)\n",
    "#koe bhe 10/random\n",
    "data.head(10)\n",
    "#0 -9 start\n",
    "data.info()\n",
    "#pora data ke information dy deta hai #all detail\n",
    "#including non null value,es data mein 13320 means 13320 non null value valid hein\n",
    "data.area_type.unique()\n",
    " idea krta ka area_type mein kia kya hai,4 kes ke type a gaee area_type mein\n",
    "data.area_type.value_counts()\n",
    "kes area mein ketna makan hain,wo a gaya\n",
    "\n",
    "data.availability.unique()\n",
    "data.avaiability ke bhe unique dekh leta hein\n",
    "\n",
    "data.location.unique()\n",
    "mujha sarae location ka name parhna hein but sahe sai nhe parh pa raha,list a rahe\n",
    "for loop laga kr print karwa liafor a in data.location.unique():\n",
    "**** for a in data.location.unique():\n",
    "    print(a)\n",
    "hum yahan names ko chota bhe kr sakta..lakin yahan phase 1 phase 2 lekha howa..koe as such masla \n",
    "nhe hai\n",
    "\n",
    "\n",
    "#        ============ Get Percentage by using function n Condition, By Lambda and By Comrephension===========\n",
    "\n",
    "\n",
    "134.   Assign GRADE  USING   BY CONDITION and  .apply()\n",
    " * Auto Internal loop chala ga .apply() sai akk akk percentage pr\n",
    "make function\n",
    "def assign_grade(percentage):\n",
    "    if percentage>=90:\n",
    "        return \"A1\"\n",
    "        \n",
    "result['Grade']=result.Percentage.apply(assign_grade)\n",
    "result\n",
    "\n",
    "\n",
    "135.              Lambda Function\n",
    "use only on that particular cell;for Quik job done for short work or for not repeated work therefore wont make function\n",
    "\n",
    "result['Grade1']=result.Percentage.apply(lambda x: \"A1\" if x>=90 else \"A\"if x>=80 else \"B\" if x>=70 else \"C\" if x>=60 else \"D\" if x>=50 else \"Fails\") \n",
    "result\n",
    "\n",
    "Lambda apply kru,Lambda ka pass jo value aya ge wo variable x mein gera ge\n",
    "yahan elif nhe chalta ,else if alag chala ga,and \"A\" if ka pecha\n",
    "\n",
    "136. # by List Compreshension \n",
    "# same cheaz utha kr list comprehension mein dal du\n",
    "#by for loop\n",
    "\n",
    "result['Grade2']=[\"A1\" if x>=90 else \"A\"if x>=80 else \"B\" if x>=70 else \"C\" if x>=60 else \"D\" if x>=50 else \"Fails\" for x in result.Percentage] \n",
    "result\n",
    "\n",
    "first list mein dala ,es pr loop chala, for x in result.Percentage \n",
    "\n",
    "All Three:-\n",
    "#1.result['Grade']=result.Percentage.apply(assign_grade)\n",
    "result\n",
    "\n",
    "#2.result['Grade1']=result.Percentage.apply(lambda x: \"A1\" if x>=90 else \"A\"if x>=80 else \"B\" if x>=70 else \"C\" if x>=60 else \"D\" if x>=50 else \"Fails\") \n",
    "result\n",
    "\n",
    "#3.result['Grade2']=[\"A1\" if x>=90 else \"A\"if x>=80 else \"B\" if x>=70 else \"C\" if x>=60 else \"D\" if x>=50 else \"Fails\" for x in result.Percentage] \n",
    "result\n",
    "\n",
    "137.# zip\n",
    "#bund krte hai\n",
    "# zip eg # 2 list\n",
    "a=[1,2,3,4,5,6]\n",
    "b=[7,8,9,10,11,12]\n",
    "zip(a,b)\n",
    "#zip kr du a and b ko#es object ko cast kar du ,list sai# list sai type cast kr du\n",
    "list(zip(a,b))\n",
    "#jaisa zip chalte hai ak yahan sai ak yahan sai,pair banta jata hai,one one ka pair\n",
    "Ans:- [(1, 7), (2, 8), (3, 9), (4, 10), (5, 11), (6, 12)]\n",
    "\n",
    "138. Looping Row Wise\n",
    "\n",
    "# * abhe tuk looping column wise chal rahe thee,pora column pr loop laga raht ha,\n",
    "#ub student ka reocrd wise check krna hai,hum kara ga row wise\n",
    "\n",
    "[result.iloc[a] for a in range(1)] Ans row with column\n",
    "# Ans LIKE \n",
    "#:[Name           Rauf\n",
    "# Python           78\n",
    "\n",
    "#[ for Py, Pd, Np, St,Fl,Ml in zip (result.Python,result.Pandas,result.Numpy,result.Stats,result.Flask,result.ML)]\n",
    "#tu ya 5 values unzip ho jayn ge\n",
    "# ya zip ho kr es tarha ho jaya ge (78,78,98,67,76,99)\n",
    "# unzip krna ka lia \n",
    "#(a,b,c,d,e,f)=(78,78,98,67,76,99)\n",
    "\n",
    "# 1st ZIP\n",
    "[(Py, Pd, Np, St,Fl,Ml) for Py, Pd, Np, St,Fl,Ml in zip (result.Python,result.Pandas,result.Numpy,result.Stats,result.Flask,result.ML)]\n",
    "\n",
    "#2nd Separate Function ,COndition check\n",
    "# NESTED IF ,*all condition true tu true kr du\n",
    "\n",
    "LIKE:- #def status(a)\n",
    "   # Py, Pd, Np, St,Fl,Ml=a\n",
    "    #unzip kr dia,ub sara marks =marks\n",
    "    if Py>=50:\n",
    "        #pass\n",
    "        if Pd>=50:\n",
    "           return \"Pass\" #agar all 5 mein condition pass ho gae tub pass\n",
    "        else:\n",
    "           return \"Fail\"\n",
    "    else:\n",
    "       return \"Fail\"\n",
    "\n",
    "#3rd. COndition CHeck by Loop\n",
    "result['Status']=[status(a) for a in zip (result.Python,result.Pandas,result.Numpy,result.Stats,result.Flask,result.ML)]\n",
    "# zip ho kr pora tuple aya ga  ,a, mein chala jaya ga sara values\n",
    "# a ka lia status ka function call kia,akk akk true check howa,then pass,,agar akk flase tu direct fail\n",
    "result\n",
    "\n",
    "\n",
    "#         =========================Transforming Data   # Mapping===================================\n",
    "    \n",
    "139. # mapping two series    x.map(y)\n",
    "\n",
    "import pandas as pd\n",
    "#create two series object to demonstrate Mapping\n",
    "x=pd.Series({\"one\":1,\"two\":2,\"three\":3})\n",
    "y=pd.Series({1:\"a\",2:\"b\",3:\"c\"})\n",
    "# 2 series hein, akk series ke value,dosri series ke keys hein\n",
    "x                           y                   x.map(y)\n",
    "one      1             1    a                 one      a\n",
    "two      2             2    b                 two      b\n",
    "three    3             3    c                 three    c\n",
    "dtype: int64         dtype: object            dtype: object\n",
    "\n",
    "#map values in x to values in y\n",
    "x.map(y)\n",
    "\n",
    "\n",
    "140.\n",
    "s=pd.Series(['cat','cow','dog'])\n",
    "print(s)\n",
    "print(\"Mapping: \")\n",
    "s.map({\"cat\":\"kitten\",\"cow\":\"calf\"})\n",
    "# s ke series ko s.map({\"cat\":\"kitten\",\"cow\":\"calf\"}) es dictionary ka sath ma kr du\n",
    "\n",
    "0    cat              0    kitten\n",
    "1    cow              1      calf\n",
    "2    dog              2       NaN         \n",
    "dtype: object         dtype: object\n",
    "        \n",
    "141. # Data Frame Mapping\n",
    "data=pd.DataFrame({'Country':['Pakistan','Saudia','Turkey','Palestine','Oman'],'Pop':[256,36,85,5,5]})\n",
    "data\n",
    "capitals={'Oman':'Muscat','Saudia':'Riyad','Pakistan':'Islamabad',\"Turkey\":'Ankara'}\n",
    "#LIKE   \n",
    "    Country     Pop\n",
    "0   Pakistan    256\n",
    "\n",
    "data['Capitals']=data.Country.map(capitals)\n",
    "data\n",
    "\n",
    "        Country   Pop   Capitals\n",
    "0       Pakistan  256   Islamabad\n",
    "1       Saudia    36    Riyad\n",
    "2\n",
    "3.      Palestine  5    NaN\n",
    "\n",
    "142.\n",
    "import pandas as pd\n",
    "***** Practice ths dataframe\n",
    "\n",
    "df = pd.DataFrame([('carrot', 'red', 1), ('papaya', 'yellow', 0),('mango', 'yellow', 0), ('apple', 'red', 0)], \n",
    "columns=['species', 'color', 'type'])\n",
    "mappings = {'carrot': 'veg','papaya': 'fruit'}\n",
    "\n",
    "print(\"Dataframe before Mapping: \")\n",
    "print(df)\n",
    "#ya ak data frame banaya tuple ka through\n",
    "\n",
    "df['type_name'] = df['species'].map(mappings)\n",
    "print(\"Dataframe after Mapping: \")\n",
    "print(df)\n",
    "\n",
    "#map kr ka new series banata hai\n",
    "#ya hum na kia ya hai type 1 ,0 a rahe..user ko samjh nhe aya ga,ub hum na user ko batana ka species \n",
    "#ke type kia hein\n",
    "\n",
    "143.data = pd.DataFrame({'food': ['bacon', 'pulled pork', 'bacon','Pastrami', 'corned beef', 'Bacon','pastrami', 'honey ham', 'nova lox'],\n",
    "'ounces': [4, 3, 12, 6, 7.5, 8, 3, 5, 6]})\n",
    "data\n",
    "meat_to_animal = {'bacon': 'pig','pulled pork': 'pig','pastrami': 'cow','corned beef': 'cow','honey ham': 'pig','nova lox': 'salmon'\n",
    "}\n",
    "\n",
    "#meat to animal ke dictionary hai,kon sai gosht kes janwar ka hai\n",
    "#ub es dictionary ko map krna .ka hur meat ke source kia hai\n",
    "\n",
    "data['Meat_to_animal']=data.food.map(meat_to_animal)\n",
    "data\n",
    "        food     ounces   Meat_to_animal\n",
    "0       bacon    4.0      pig\n",
    "3       Pastrami 6.0      NaN\n",
    "\n",
    "#ub opar Pastrami Nan dekha raha,kuu ka ,kuu ka meat to animal ka data mein wo small mein hai pastrami,same bacon\n",
    "\n",
    "data.food.apply(lambda x:x.lower())\n",
    "\n",
    "# ub es na auto internal loop chala kr sub ko small kr dia data.food mein\n",
    "\n",
    "data\n",
    "\n",
    "144. # Lamba Practice & Vectorized Operation\n",
    "#lambda ke aisa he ak pratice\n",
    "#data.ounces.apply(lambda x: x+0)\n",
    "#OR\n",
    "# as its vactorized operation ,we can also write,other then Lamda\n",
    "#like\n",
    "#data=data.ounces+20\n",
    "#data\n",
    "\n",
    "145.# REPLACING VALUES by Lambda\n",
    "# Transformation mein kaee jaghoon pr humyn replacing bhe krne pr jate hai\n",
    "data1 = pd.Series([1., -999., 2., -999., -1000., 3.])\n",
    "data1\n",
    "#-999 bohat chote value es ko zero kr du\n",
    "#ub ak tareka tu Lambda sai kr du,dosra Replacing\n",
    "\n",
    "#Lambda sai\n",
    "data1.apply(lambda x:0 if x <=-999 else x )\n",
    "\n",
    "# x ka pass value ayan ge data ke series sai.\n",
    "\n",
    "\n",
    "#*jub hum column bolata,tu one by one value nekalta ,loop ke tarha,us mein kamal lambda ka nhe,vectrize \n",
    "#operation ka hai,pecha loop chal raha hota hai\n",
    "#*** tu series ka fayda he yahe hai ka jo vectorize operation perform krta hein ,wo pori series pr\n",
    "#apply ho jata hai\n",
    "#list pr apply hai he nhe,apply series ka function hai\n",
    "\n",
    "#OR By  Replace\n",
    "\n",
    "data1.replace(-999,0)\n",
    "#LAKIN\n",
    "#* es mein problem ya ho ge ka wohe value replace ho ge,1000 wale nhe ho ge\n",
    "\n",
    "        ===================DISCRETIZATION AND BINNING================\n",
    "\n",
    "146.     #Binning   .cut()\n",
    "#Binning\n",
    "ages = [20, 22, 25, 27, 21, 23, 37, 31, 61, 45, 41, 32] # Container\n",
    "\n",
    "#Lets divide these into bins of 18 to 25/(18, 25],26 to 35,36 to 60 and finally 61 and older.TO do so,called categories\n",
    "# you have to use cut,a function in pandas.\n",
    "\n",
    "bin=[18,25,35,60,100]\n",
    "cats=pd.cut(ages,bin)\n",
    "cats\n",
    "#cats=category ,wo jo opar hamara pass container data tha ,wo ub categorical data mein convert ho jaya ga\n",
    "\n",
    "#[(18, 25], (18, 25], (18, 25], (25, 35] ya kia dy raha hai    # Categories\n",
    "# ya kha raha hai jo phale age hai 20, wo[(18, 25] ke category mein hai,ese tarha 4th age 27\n",
    "# (25, 35]  ke category mein hai\n",
    "\n",
    "#length 12 means 12 ages in container \n",
    "#Categories 4\n",
    "\n",
    "#( ] called open and closed intervals\n",
    "# ** (8 , =it means 8 included\n",
    "# ** 25] = means 25 not included\n",
    "# matlab 8 sai shuru ho or 25 ka undar\n",
    "\n",
    "\n",
    "147.# category codes / clusters  .codes\n",
    "#category codes\n",
    "cats.codes\n",
    "#phale category ko 0 index bol dia,dosri category ko 1 index\n",
    "# (18, 25] 0 index \n",
    "# (25, 35] 1 index and so on\n",
    "# in machine laguage category called clusters\n",
    "\n",
    "148.# category codes can be replace by number or name  labels\n",
    "cats=pd.cut(ages,bin , labels=['Bacha hai','Jawan hai','Old hai','Rub ka pyara'])\n",
    "cats\n",
    "pd.value_counts(cats)\n",
    "\n",
    "#              =================Permutation and Random Sampling=======================\n",
    "149.\n",
    "import numpy as np\n",
    "df = pd.DataFrame(np.arange(5 * 4).reshape((5, 4)))\n",
    "df\n",
    "# 5*4 means 20 arange\n",
    "    0\t1\t2\t3\n",
    "0\t0\t1\t2\t3\n",
    "1\t4\t5\t6\t7\n",
    "2\t8\t9\t10\t11\n",
    "3\t12\t13\t14\t15\n",
    "4\t16\t17\t18\t19\n",
    "\n",
    "150.#now generate random number\n",
    "sampler=np.random.permutation(5)\n",
    "sampler\n",
    "\n",
    "ANs: array([4, 2, 0, 1, 3])\n",
    "    \n",
    "151. # take\n",
    "df.take(sampler)\n",
    "# data ka undar sai ya wala sampler ly lu\n",
    "df\n",
    "# statics mein bohat important hota hai sampling concept,agar sampling theak nhe kr raha tu result\n",
    "#theak nhe ayn ga\n",
    "\n",
    "\n",
    "#one of the method of sampling is Random Sampling\n",
    "# eg take few students weight out of class,means got few result and apply on all population\n",
    "#It is a subset containing the characteristics of a larger population.\n",
    "\n",
    "152.df.sample(5)\n",
    "\n",
    "    0\t1\t2\t3\n",
    "0\t0\t1\t2\t3\n",
    "4\t16\t17\t18\t19\n",
    "1\t4\t5\t6\t7\n",
    "2\t8\t9\t10\t11\n",
    "3\t12\t13\t14\t15\n",
    "\n",
    "\n",
    "\n",
    " ===============Computing Indicator/DUmmy Variables==================\n",
    "#encoding of data\n",
    "#jub bhe hum kese data ko machine sai pass karwata hein,machine 0 ya 1 samjhte hai\n",
    "#DUmmy data used for Nominal/name/noun data to change  string in machine language\n",
    "#hum dummy value es lia get krta hein ka hamara nominal data (which have ST value too ,then convert integer) but ,understand \n",
    "tu machine language convert hu ,es tarha ka us ke nominality bhe bakee raha\n",
    "#es lia hum banata dummy variables\n",
    "153. # Dummy Variables   get_dummies()\n",
    "data=pd.read_excel('SaleData.xlsx',index_col='OrderDate')\n",
    "data\n",
    "\n",
    "#see one hot encoding image on google\n",
    "# see in image\n",
    "# S.no  Color           Sno   RedColor   Blue COlor    Green COlor\n",
    "#  0     Red            0      1          0             0\n",
    "#  1     Blue           1      0          1             0\n",
    "#  2     Green          2      0          0             1\n",
    "# 3      Blue           3      0          1             0\n",
    "\n",
    "# ub ya red ka dummies mel gaya    1 0 0\n",
    "# ya one hot encode ho gaya\n",
    "# necha jub Central ho ga tu Central true,East n West False\n",
    "\n",
    "154.\n",
    "data.Region.value_counts()\n",
    "\n",
    "pd.get_dummies(data.Region)\n",
    "#dummies hasil kru,data,region ka undar hein\n",
    "\n",
    "           Central  East    West\n",
    "OrderDate\n",
    "2018-01-06\tFalse\tTrue\tFalse\n",
    "2018-01-23\tTrue\tFalse\tFalse\n",
    "\n",
    "155. # DUmmy data in whole data where there is Nominal/name/noun\n",
    "# ub pora data mein jahan nominal data us ke dummies\n",
    "pd.get_dummies(data)\n",
    "\n",
    "#*#data able to process ho gaya machine model mein process krna ka lia lakin columns barh gaya\n",
    "\n",
    "           Units\tUnit_price\tSale_amt\tRegion_Central\tRegion_East\tRegion_West\t Manager_Douglas\tManager_Hermann\tManager_Martha\tManager_Timothy\t...\tSalesMan_Michael\tSalesMan_Shelli\tSalesMan_Sigal\tSalesMan_Stephen\tSalesMan_Steven\tItem_Cell Phone\tItem_Desk\tItem_Home Theater\tItem_Television\tItem_Video Games\n",
    "OrderDate\n",
    "2018-01-06\t95.00\t1198.000\t113810.00\t       False\t   True        \tFalse\t  False\t                    False\t  True\t\n",
    "\n",
    "# How it works# remove punctuation and stop words# 1st TOkenize into words# each words has it token,\n",
    "# remove duplicate words\n",
    "\n",
    "\n",
    "156.\n",
    "df=pd.DataFrame({'key':['b','a','c','d','e','a'],'data1':range(6)})\n",
    "df\n",
    "pd.get_dummies(df['key'])\n",
    "# see unique values le a,b,c ,d,e \n",
    "#us ka token bana\n",
    "#agar eg 50k workds hota ,tu ak word ka lia 50K ka vector hota,jis mein akk true hota ,bakee sara False\n",
    "\n",
    "      a\t      b\t      c     \td\t  e\n",
    "0\tFalse\tTrue\tFalse\tFalse\tFalse\n",
    "1\tTrue\tFalse\tFalse\tFalse\tFalse\n",
    "2\tFalse\tFalse\tTrue\tFalse\tFalse\n",
    "3\tFalse\tFalse\tFalse\tTrue\tFalse\n",
    "4\tFalse\tFalse\tFalse\tFalse\tTrue\n",
    "5\tTrue\tFalse\tFalse\tFalse\tFalse\n",
    "\n",
    "157. # By Loop\n",
    "df['new']=df['key'].apply(lambda x:1 if x=='a' else 2 if x=='b' else 3 if x=='c' else 4)\n",
    "\n",
    "df\n",
    "\n",
    "158.\n",
    "#              =============================         Data Wrangling            ==================================\n",
    "\n",
    "#              =============================   Join , Combine and Re-Shape     ==================================\n",
    "\n",
    "159.\n",
    "# different sources sai data combine ho raha ya alag ho raha es ko Wrangling khata hein\n",
    "\n",
    "#akk tu data transformation tha ,jis mein data ka undar ghus kr changes kee,values mein changes ke\n",
    "#Wrangling mein values change nhe krta,data ke shape change krta hein, 2 dataframes add kr raha hota hein\n",
    "#kuch filter kr ka data mein sai nekal raha hota hein, 2 data sets ko combine kr raha hota hein\n",
    "#re-shape kr raha hota hein\n",
    "\n",
    "# COMBINING AND MERGING DATA SETS\n",
    "#Data ko apis mein merge krna.ya array ke tarha jo pecha parha ,waisa combine nhe hai\n",
    "# ya combine hai different kesam ka\n",
    "\n",
    "\n",
    "160.#   pd.concat  axis=0 (by default) / Horizontal  / Increase in Rows ( When rown n COlumns are Equal)\n",
    "\n",
    "df0=pd.read_excel(\"test_data (1).xlsx\",sheet_name=0)\n",
    "df1=pd.read_excel(\"test_data (1).xlsx\",sheet_name=1)\n",
    "df2=pd.read_excel(\"test_data (1).xlsx\",sheet_name=2)\n",
    "\n",
    "df0\n",
    "df1\n",
    "df2\n",
    "\n",
    "#3 sheets hein excel file mein\n",
    "# sheet df 0 , df 1 ,df2 rows are same ,but df 0 and df 1 columns same but row different\n",
    "\n",
    "#sheet 3 mein columns change hein ,sheet 2 and 1 mein same hein\n",
    "#akk concate ka function mojood hota hai,concate kia krta hai\n",
    "#object leta hai list form ka undar or un ko concatenate kr deta hai\n",
    "#concatenate krna ka lia hum na numpy mein dekha tha ka kia cheaz zarori hai\n",
    "#* ka agr mein horizontally concatenate kr raha hun ,tu rows 4 ya 5 nhe hone chahya,akk extra na rha\n",
    "#jaya necha ya opar\n",
    "# * agar vertically concatenate kr raha hu,tu column barabar hona chahya,extra na a jaya\n",
    "\n",
    "# ub 2 different sources sai aya howa data ko concatenate kr raha hein,column donu ka check kr lia\n",
    "# ak jaisa hee hein\n",
    "\n",
    "pd.concat([df0,df1])\n",
    "\n",
    "#df1,df0 ka necha murge ho gaee\n",
    "#ya donu horizontal axis ka opar concatenate ho gae\n",
    "# lakin index repeat ho gaya\n",
    "\n",
    "# ** jub necha add ho raha hai tu rows mein izafa ho raha hai,axis 0 mein increase ho raha hai\n",
    "# agar column barh jayn ga tu axis 1 mein increase ho ga\n",
    "\n",
    "pd.concat([df0,df1])\n",
    "\n",
    "sales_man_id    sales_man_name         sales_man_city      product_id manager\n",
    "0\t1\t        Asad\t                Karachi\t             123\t   Jawed\n",
    "1\t2\t        Sumair\t                Lahore\t             123\t   Jawed\n",
    "0\t11\t        Ahmed\t                Karachi\t             123\t   Jawed\n",
    "1\t22\t        Umer\t                Lahore\t             123\t   Jawed\n",
    "\n",
    "\n",
    "161. #  pd.concat  axis=1  / Vertical  / Increase in Columns  ( When rown n COlumns are Equal)\n",
    "\n",
    "pd.concat([df0,df1],axis=1)\n",
    "\n",
    "#axis 1 sai increae kr raha ub\n",
    "# donu ka 8 records hein,lag jayn ga\n",
    "#columns barh gaya\n",
    "\n",
    "    sales_man_id sales_man_name sales_man_city  product_id\tmanager  sales_man_id  sales_man_name  sales_man_city  product_id\tmanager\n",
    "0       1\t       Asad\t           Karachi\t       123\t     Jawed\t     11\t             Ahmed\t        Karachi\t   123\t    Jawed\n",
    "\n",
    "162. # 2 sheet rows equal but not column equal\n",
    "\n",
    "pd.concat([df0,df2])\n",
    "\n",
    "#ub hum df2 ko add kr raha jis ka column kam hein\n",
    "\n",
    "#NOTE: numpy mein ya allow nhe kr raha tha\n",
    "#jo column overlap tha wo la lia,\n",
    "#salesmanid mein region sales and amount nhe tha us ko NaN kr dia\n",
    "# ak trha ke mapping mera khayal mein\n",
    "#tu donu ka size barbar krna ka lia,Nan fill kr dia\n",
    "#es ka data tumhara pass nhe ta tum na NaN fill kr lia,tumhara data es ka pass nhe tha es na Nan\n",
    "# fill kr lia,other then overlapping\n",
    "#es mein ya issue ata ka jub hum different source sai data leta hein,tu hamara pass bohat sara columns\n",
    "#Nan ka add ho jata hein\n",
    "#simple concatenation mein ya issue ata hai\n",
    "\n",
    "            sales_man_id sales_man_name\t  sales_man_city\tproduct_id\tmanager\tRegion\tSales\tAmount\n",
    "0\t           1.0\t      Asad\t          Karachi\t           123.0\tJawed\tNaN\t     NaN\tNaN\n",
    "1\t           2.0\t      Sumair\t      Lahore\t           123.0\tJawed\tNaN\t     NaN\tNaN\n",
    "2\t           3.0\t      Farjad\t      Karachi\t           145.0\tNajam\tNaN\t     NaN\tNaN\n",
    "0\t           NaN\t      Asad\t          NaN\t               NaN\t    NaN\t      A\t   100.0\t100000.0\n",
    "1\t           NaN\t      Hussain\t      NaN\t               NaN\t    NaN\t      B\t   300.0\t450000.0\n",
    "2\t           NaN\t      Ali\t          NaN\t               NaN\t    NaN\t      C\t    234.0\t125000.0\n",
    "\n",
    "\n",
    "163.# .reset_index()\n",
    "# sara index both data ka tarteeb sai\n",
    "\n",
    "pd.concat([df0,df2]).reset_index()\n",
    "\n",
    "    Index   sales_man_id sales_man_name\t  sales_man_city\tproduct_id\tmanager\tRegion\tSales\tAmount\n",
    "1\t 0          1.0\t      Asad\t          Karachi\t           123.0\tJawed\tNaN\t     NaN\tNaN\n",
    "2\t 1          2.0\t      Sumair\t      Lahore\t           123.0\tJawed\tNaN\t     NaN\tNaN\n",
    "3\t 2          3.0\t      Farjad\t      Karachi\t           145.0\tNajam\tNaN\t     NaN\tNaN\n",
    "4\t 0          NaN\t      Asad\t          NaN\t               NaN\t    NaN\t      A\t   100.0\t100000.0\n",
    "5\t 1          NaN\t      Hussain\t      NaN\t               NaN\t    NaN\t      B\t   300.0\t450000.0\n",
    "6\t 2          NaN\t      Ali\t          NaN\t               NaN\t    NaN\t      C\t    234.0\t125000.0\n",
    "\n",
    "\n",
    "164.#              .merge\n",
    "pd.merge(df0,df2)\n",
    "#ub chuka ak column hee sirf merge ho raha tu ,on batana nhe parta ,wo khud he murge kr leta hai\n",
    "\n",
    "#wo df0 mein gaya,phala salesman hai Asad\n",
    "#ya jaya ga,dekha ga ka df2 mein Asad ka map ho raha ha kahee,,,us na dekha ho raha ,ya data agaya\n",
    "#df0 ka Asad ko check kia us na df2 mein...or df2 ka pora record df1 ka asad mein dal dia\n",
    "#means df0 ke id 1 ka aga df2 asad ka record lag gaya\n",
    "\n",
    "#df0 ke id 2 pr sumair tha..sumair df2 mein nhe mela,sumair shamil nhe howa\n",
    "\n",
    "#map kr raha hai ,jo columns ke value map ho rahe hai,wo record wahan sai utha kar es ka aga laga raha \n",
    "#hai\n",
    "\n",
    "\tsales_man_id\tsales_man_name\t     sales_man_city\t   product_id\tmanager\tRegion\tSales\tAmount\n",
    "0\t1\t               Asad\t                   Karachi\t     123\t        Jawed\tA\t100\t   100000\n",
    "1\t4\t              Hassan\t               Lahore\t     567\t        Najam\tG\t129\t   125000\n",
    "2\t6\t              Kashif\t               Hyderabad\t 234\t        Faisal\tF\t123\t   825000\n",
    "3\t7\t               Sana\t                   Lahore\t     567\t       Faisal\tD\t231\t   652000\n",
    "\n",
    "# * Map          : a sai b ,matched elements ka data map ,other data which doesnt match shows Nan\n",
    "# * Concatenate  : Both list add horizntally(row wise) or vertically (columns wise) both data frames add,if Columns and rows\n",
    "#                  are equal\n",
    "#                  if not equal then merge match figures values of both data frame,others NaN\n",
    "# * Merge        : a sai b ,matched elemets ka data map,other unmatched elements not shown in the list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "165.      #strip\n",
    "#The strip() method removes any leading, and trailing whitespaces. Leading means at the beginning of the string, \n",
    "#trailing means at the end. You can specify which character(s) to remove, if not, any whitespaces will be removed\n",
    "\n",
    "#df2 mein Fatima mein space hai,es lia nhe utha raha\n",
    "#check krna ka lia\n",
    "\n",
    "df2['sales_man_name']=='Fatima'\n",
    "\n",
    "#ub fatima ke space khatam krna ka lia\n",
    "#Lambda use kara ga with strip\n",
    "df2['sales_man_name']=df2.sales_man_name.apply(lambda x: x.strip())\n",
    "df2\n",
    "\n",
    "\n",
    "166.#                       merge how:inner merge  (default:How/inner) Left to Right /By Default\n",
    "pd.merge(df0,df2)   \n",
    "#ub Fatima bhe a gaya\n",
    "\n",
    "# *left or right ko jub hum na merge kia,tu wo left ka sara record dhundta raha right mein,or right\n",
    "#ka sara record ly aya\n",
    "\n",
    "# **ya inner merge khalata hai,it means interection ,means jo jo record match hota hein wo select ho jata \n",
    "#hein or jo match nhe hota,wo drop ho jata hein\n",
    "# default mein merge how mein inner hai\n",
    "\n",
    "#donu match hu ga,intersept hu ga tu he ayan ga\n",
    "\n",
    "\n",
    "\n",
    "166. #   pd.merge(df2,df0)  (Right to Left)\n",
    "#record same raha ga ,sirf sorting change ho jaya ge\n",
    "\n",
    "   sales_man_name\tRegion\tSales\tAmount\tsales_man_id\tsales_man_city\tproduct_id\tmanager\n",
    "0\tAsad\t        A\t       100\t100000\t1\t                      Karachi\t123\tJawed\n",
    "1\tSana\t        D\t       231\t652000\t7\t                      Lahore\t567\tFaisal\n",
    "2\tFatima\t        E\t       324\t145000\t8\t                      Karachi\t345\tNajam\n",
    "3\tKashif\t        F\t       123\t825000\t6\t                      Hyderabad\t234\tFaisal\n",
    "4\tHassan\t        G\t      129\t125000\t4\t                      Lahore\t567\tNajam\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "167. #  merge how :outer merge \n",
    "\n",
    "pd.merge(df2,df0,how='outer')\n",
    "#inner joint ,jo match krta hai wo ly kr ata hai\n",
    "#or outer joint:donu ka sara record laya ga\n",
    "#masla ya ho ga ,ka jub ak ka sara record laya ga ,jo match hun ga,un ko joint\n",
    "#or ak ka record agar dosra sai match nhe hu ga tu jo extra columns hu ga,un ko Nan kara ga.\n",
    "\n",
    "\n",
    "          sales_man_name\tRegion\tSales\tAmount\t    sales_man_id\tsales_man_city\tproduct_id\tmanager\n",
    "0\t           Asad\t         A\t    100.0\t100000.0\t      1.0          \tKarachi\t       123.0\tJawed\n",
    "1\t           Hussain\t     B\t    300.0\t450000.0\t      NaN\t        NaN\t            NaN\t     NaN\n",
    "2\t           Ali\t         C\t    234.0\t125000.0\t      NaN\t        NaN\t            NaN\t     NaN\n",
    "3\t           Sana\t         D\t   231.0\t652000.0\t      7.0\t        Lahore\t        567.0\tFaisa\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7468c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba06a399",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
